{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_eval(y_true, y_pred):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.metrics import precision_score\n",
    "    from sklearn.metrics import recall_score\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='micro')\n",
    "    pr = precision_score(y_true, y_pred, average='micro')\n",
    "    recall = recall_score(y_true, y_pred, average='micro')\n",
    "    print('acc = {}, f1 = {}, pr = {}, recall = {}'.format(acc, f1, pr, recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=100, activation='logistic', max_iter=500, batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', batch_size=200, hidden_layer_sizes=100,\n",
       "              max_iter=500)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.61777051e-06, 3.07702857e-05, 4.77922998e-04, 5.42544518e-03,\n",
       "        1.93008466e-07, 8.73714400e-05, 1.25508631e-06, 2.94671005e-06,\n",
       "        9.93914794e-01, 5.36834663e-05]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9541904761904761, f1 = 0.9541904761904761, pr = 0.9541904761904761, recall = 0.9541904761904761\n"
     ]
    }
   ],
   "source": [
    "do_eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes\n",
    "1. 3 layer(input, 50 neuron, output ) 0.946\n",
    "2. 4 layer (input, 50, 50, output) 0.958\n",
    "3. 3 layer (input, 100, output) 0.96\n",
    "4. 4 layer (input, 100, 100, output) 0.968\n",
    "5. 3 layer (input, 100, output), relu 0.96, logistic 0.95, tanh 0.94, identity 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with torch\n",
    "pytorch core component:\n",
    "+ torch.Tensor\n",
    "+ torch.nn, torch.functional\n",
    "+ torch.optim\n",
    "+ torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "x = torch.ones(1, requires_grad=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## auto grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x + 2\n",
    "z = y * y * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([12.])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = torch.nn.Linear(1, 1)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc(x)\n",
    "        output = self.relu(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight torch.Size([1, 1])\n",
      "fc.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "net = Perceptron()\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a 3-Layer NN\n",
    "https://medium.com/biaslyai/pytorch-introduction-to-neural-network-feedforward-neural-network-model-e7231cff47cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 layer NN\n",
    "class Feedforward(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Feedforward, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.hid1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(self.hidden_size, 10)\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.relu(self.hid1(x))\n",
    "        output = self.softmax(self.output(hidden))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. define a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feedforward(\n",
       "  (hid1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (output): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Feedforward(784, 50)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hid1.weight torch.Size([50, 784])\n",
      "hid1.bias torch.Size([50])\n",
      "output.weight torch.Size([10, 50])\n",
      "output.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39200"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784* 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.LongTensor([int(x) for x in y_train])\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.LongTensor([int(x) for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5152e-07, 3.0932e-09, 2.3359e-10, 1.0828e-26, 1.8537e-23, 5.9487e-15,\n",
       "         2.6862e-29, 1.0000e+00, 1.2232e-15, 1.5186e-38]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X_train_tensor[0].reshape([1, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. define loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss before training 2.3226265907287598\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "y_pred_tensor = model(X_test_tensor)\n",
    "before_train_loss = criterion(y_pred_tensor, y_test_tensor)\n",
    "print('Test loss before training' , before_train_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 2.3230514526367188\n",
      "epoch 100, train loss 1.7942602634429932\n",
      "epoch 200, train loss 1.6264363527297974\n",
      "epoch 300, train loss 1.604680061340332\n",
      "epoch 400, train loss 1.5978587865829468\n",
      "epoch 500, train loss 1.593381643295288\n",
      "epoch 600, train loss 1.590737223625183\n",
      "epoch 700, train loss 1.5884721279144287\n",
      "epoch 800, train loss 1.586982011795044\n",
      "epoch 900, train loss 1.585553765296936\n",
      "epoch 1000, train loss 1.5843391418457031\n",
      "epoch 1100, train loss 1.5832449197769165\n",
      "epoch 1200, train loss 1.5826247930526733\n",
      "epoch 1300, train loss 1.5819228887557983\n",
      "epoch 1400, train loss 1.581292748451233\n",
      "epoch 1500, train loss 1.580118179321289\n",
      "epoch 1600, train loss 1.5792722702026367\n",
      "epoch 1700, train loss 1.578666090965271\n",
      "epoch 1800, train loss 1.5779352188110352\n",
      "epoch 1900, train loss 1.577486276626587\n",
      "335.93100905418396 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "model.train()\n",
    "epoch = 2000\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass\n",
    "    y_pred_tensor = model(X_train_tensor)\n",
    "    train_loss = criterion(y_pred_tensor, y_train_tensor)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"epoch {}, train loss {}\".format(epoch, train_loss.item()))\n",
    "    # backword pass\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "toc = time.time()\n",
    "print(toc - tic, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. do eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tensor = model(X_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_for_skearn = [str(v) for v in torch.argmax(y_pred_tensor, dim=1).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.8601904761904762, f1 = 0.8601904761904762, pr = 0.8601904761904762, recall = 0.8601904761904762\n"
     ]
    }
   ],
   "source": [
    "do_eval(y_pred_for_skearn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with CNN(conv1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_train_cnn = X_train_tensor.reshape([X_train_tensor.size()[0], 1, 784])\n",
    "y_train_cnn = torch.LongTensor([int(x) for x in y_train])\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "X_test_cnn = X_test_tensor.reshape([X_test_tensor.size()[0], 1, 784])\n",
    "y_test_cnn = torch.LongTensor([int(x) for x in y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=3, kernel_size=5),\n",
    "            torch.nn.ReLU()\n",
    "        ) # [N, 3, 784 - 5 + 1 = 780]\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(3, 1, 5),\n",
    "            torch.nn.ReLU()\n",
    "        )# [N, 1, 780 - 5 + 1 = 776]\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(776, 10),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv1d(1, 3, kernel_size=(5,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv1d(3, 1, kernel_size=(5,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=776, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_model = SimpleCNN()\n",
    "simple_cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight torch.Size([3, 1, 5])\n",
      "conv1.0.bias torch.Size([3])\n",
      "conv2.0.weight torch.Size([1, 3, 5])\n",
      "conv2.0.bias torch.Size([1])\n",
      "fc.0.weight torch.Size([10, 776])\n",
      "fc.0.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in simple_cnn_model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0634e-05, 1.6884e-03, 2.1729e-03, 1.3160e-01, 5.3248e-03, 6.2637e-02,\n",
       "         2.0289e-02, 1.3425e-02, 2.6041e-02, 7.3674e-01]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_cnn_model(X_train_cnn[0].reshape([1, 1, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(simple_cnn_model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 2.3638970851898193\n",
      "epoch 100, train loss 1.7927191257476807\n",
      "epoch 200, train loss 1.6158777475357056\n",
      "epoch 300, train loss 1.5797147750854492\n",
      "epoch 400, train loss 1.5640912055969238\n",
      "epoch 500, train loss 1.554017186164856\n",
      "epoch 600, train loss 1.5466773509979248\n",
      "epoch 700, train loss 1.5411839485168457\n",
      "epoch 800, train loss 1.5369607210159302\n",
      "epoch 900, train loss 1.5334538221359253\n",
      "epoch 1000, train loss 1.5303295850753784\n",
      "epoch 1100, train loss 1.527725338935852\n",
      "epoch 1200, train loss 1.5254861116409302\n",
      "epoch 1300, train loss 1.5234757661819458\n",
      "epoch 1400, train loss 1.5217124223709106\n",
      "epoch 1500, train loss 1.520141363143921\n",
      "epoch 1600, train loss 1.5187087059020996\n",
      "epoch 1700, train loss 1.5174540281295776\n",
      "epoch 1800, train loss 1.516321063041687\n",
      "epoch 1900, train loss 1.5153225660324097\n",
      "16618.0857899189 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "simple_cnn_model.train()\n",
    "epoch = 2000\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass\n",
    "    y_pred_cnn = simple_cnn_model(X_train_cnn)\n",
    "    train_loss = criterion(y_pred_cnn, y_train_cnn)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"epoch {}, train loss {}\".format(epoch, train_loss.item()))\n",
    "    # backword pass\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "toc = time.time()\n",
    "print(toc - tic, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.9186190476190477, f1 = 0.9186190476190477, pr = 0.9186190476190477, recall = 0.9186190476190477\n"
     ]
    }
   ],
   "source": [
    "y_pred_cnn = simple_cnn_model(X_test_cnn)\n",
    "y_pred_for_skearn = [str(v) for v in torch.argmax(y_pred_cnn, dim=1).numpy()]\n",
    "do_eval(y_pred_for_skearn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with CNN(conv2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_train_cnn2d = X_train_tensor.reshape([X_train_tensor.size()[0], 1, 28, 28])\n",
    "y_train_cnn2d = torch.LongTensor([int(x) for x in y_train])\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "X_test_cnn2d = X_test_tensor.reshape([X_test_tensor.size()[0], 1, 28, 28])\n",
    "y_test_cnn2d = torch.LongTensor([int(x) for x in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. define and train conv network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2D(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2D, self).__init__()\n",
    "        self.conv1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        ) # [N, 6, 24, 24] => max pool => [N, 6, 12, 12]\n",
    "        self.conv2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, 5),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        )# [N, 16, 8, 8] => max pool => [N, 16, 4, 4]\n",
    "        self.fc1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(16 * 4 * 4, 120),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.fc2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(120, 84),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.fc3 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(84, 10),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN2D(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=120, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2d_model = CNN2D()\n",
    "cnn2d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.0.bias torch.Size([6])\n",
      "conv2.0.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.0.bias torch.Size([16])\n",
      "fc1.0.weight torch.Size([120, 256])\n",
      "fc1.0.bias torch.Size([120])\n",
      "fc2.0.weight torch.Size([84, 120])\n",
      "fc2.0.bias torch.Size([84])\n",
      "fc3.0.weight torch.Size([10, 84])\n",
      "fc3.0.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in cnn2d_model.named_parameters():\n",
    "    print(name, param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9993e-01, 1.6051e-09, 1.6051e-09, 1.6051e-09, 1.6051e-09, 1.6051e-09,\n",
       "         7.0012e-05, 1.6051e-09, 2.4357e-08, 1.6051e-09]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2d_model(X_train_cnn2d[0].reshape([1, 1, 28, 28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn2d_model.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train loss 2.3620917797088623\n",
      "epoch 100, train loss 2.0110065937042236\n",
      "epoch 200, train loss 1.7802565097808838\n",
      "epoch 300, train loss 1.7657623291015625\n",
      "epoch 400, train loss 1.75925874710083\n",
      "epoch 500, train loss 1.7555022239685059\n",
      "epoch 600, train loss 1.677213191986084\n",
      "epoch 700, train loss 1.66169273853302\n",
      "epoch 800, train loss 1.6586320400238037\n",
      "epoch 900, train loss 1.6566377878189087\n",
      "epoch 1000, train loss 1.4901421070098877\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "cnn2d_model.train()\n",
    "epoch = 2000\n",
    "for epoch in range(epoch):\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass\n",
    "    y_pred_cnn2d = cnn2d_model(X_train_cnn2d)\n",
    "    train_loss = criterion(y_pred_cnn2d, y_train_cnn2d)\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"epoch {}, train loss {}\".format(epoch, train_loss.item()))\n",
    "    # backword pass\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "toc = time.time()\n",
    "print(toc - tic, \"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. eval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_cnn2d = simple_cnn_model(X_test_cnn2d)\n",
    "y_pred_for_skearn = [str(v) for v in torch.argmax(y_pred_cnn2d, dim=1).numpy()]\n",
    "do_eval(y_pred_for_skearn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 48])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.nn.MaxPool1d(3, padding=0, stride=1)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.666666666666666"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "47/3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
